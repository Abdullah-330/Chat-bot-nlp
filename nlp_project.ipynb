{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EYoTdTZAr9LY"
      },
      "source": [
        "# The code represents a chatbot implemented using Python and the Natural Language Toolkit (NLTK) library. The chatbot is designed to provide responses to user queries about Hugging Face, a popular natural language processing (NLP) library. The chatbot utilizes techniques such as tokenization, lemmatization, and TF-IDF (Term Frequency-Inverse Document Frequency) to process user input and generate appropriate responses.\n",
        "\n",
        "# The chatbot begins by greeting the user and asking for their queries. It handles various types of user interactions, including greetings, expressions of gratitude, and general questions. The chatbot employs cosine similarity to determine the most relevant response from a pre-defined set of sentences. It calculates the similarity scores between the user's input and the available sentences and selects the response with the highest similarity score.\n",
        "\n",
        "# The code also includes functionality to visualize the chatbot responses using Matplotlib. The user's input and corresponding chatbot responses are stored in a DataFrame, and a bar plot is generated to display the chatbot responses over the course of the conversation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs28-p1br2Qp"
      },
      "outputs": [],
      "source": [
        "import nltk  # Importing the Natural Language Toolkit library\n",
        "import io  # Importing the io module for input/output operations\n",
        "import numpy as np  # Importing the NumPy library for array operations and computations\n",
        "import random  # Importing the random module for generating random numbers and making random selections\n",
        "import string  # Importing the string module for string manipulation functions and constants\n",
        "import warnings  # Importing the warnings module for controlling warning messages\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "warnings.filterwarnings(\"ignore\")  # Ignoring any warning messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDUCl9NL7QRY",
        "outputId": "b775ea4e-7e16-4a50-fa39-ba806ddfa6b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "f = open('/content/huggingface.txt', 'r', errors='ignore')  # Open the file 'huggingface.txt' in read mode, ignoring any decoding errors\n",
        "raw = f.read()  # Read the contents of the file into the variable 'raw'\n",
        "raw = raw.lower()  # Convert the contents of 'raw' to lowercase\n",
        "nltk.download('punkt')  # Download the necessary resources for tokenization\n",
        "nltk.download('wordnet')  # Download the necessary resources for lemmatization\n",
        "sent_tokens = nltk.sent_tokenize(raw)  # Tokenize 'raw' into a list of sentences using NLTK's sentence tokenizer\n",
        "word_tokens = nltk.word_tokenize(raw)  # Tokenize 'raw' into a list of words using NLTK's word tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZNTaZDi78Di",
        "outputId": "6d2df3e2-caa9-4e80-deb1-e12eef35ad3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hugging', 'face', 'article', 'talk', 'read']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens[:5]  # Retrieve the first two elements from the list 'word_tokens'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZNYd6Yl8LRB"
      },
      "outputs": [],
      "source": [
        "sent_tokens[:10]  # Access the first two elements of the list 'sent_tokens'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08GtKbMh8f0v"
      },
      "outputs": [],
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()   # Create an instance of the WordNet lemmatizer from NLTK\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "    # Lemmatize each token in the given list of tokens using WordNet lemmatizer\n",
        "\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "    # Create a dictionary to map punctuation characters to None using dictionary comprehension\n",
        "\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
        "    # Normalize the given text by converting it to lowercase, removing punctuation,\n",
        "    # tokenizing it into words, and then lemmatizing each word using WordNet lemmatizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kym61xDY8vSw"
      },
      "outputs": [],
      "source": [
        "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\")  # List of common greeting inputs\n",
        "GREETING_RESPONSES = [\"hi\", \"hey\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]  # List of corresponding greeting responses\n",
        "\n",
        "def greeting(sentence):\n",
        "    for word in sentence.split():  # Split the sentence into individual words\n",
        "        if word.lower() in GREETING_INPUTS:  # Check if any word in the sentence matches a greeting input\n",
        "            return random.choice(GREETING_RESPONSES)  # If a greeting is detected, return a random greeting response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXYOu1hD8-Dr"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Importing TfidfVectorizer from scikit-learn library\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity  # Importing cosine_similarity from scikit-learn library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRECOisk9JQy"
      },
      "outputs": [],
      "source": [
        "def response(user_response):\n",
        "    chatbot_response = ' '  # Initialize an empty string to store the chatbot's response\n",
        "    sent_tokens.append(user_response)  # Append the user's response to the list of sentence tokens\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=\"english\")  # Create a TfidfVectorizer object with a tokenizer and stop words\n",
        "    tfidf = TfidfVec.fit_transform(sent_tokens)  # Compute the TF-IDF matrix for the sentence tokens\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)  # Compute the cosine similarity between the last sentence token (user's response) and all other sentence tokens\n",
        "    idx = vals.argsort()[0][-2]  # Get the index of the most similar sentence token (excluding the user's response)\n",
        "    flat = vals.flatten()  # Flatten the cosine similarity values into a 1D array\n",
        "    flat.sort()  # Sort the cosine similarity values in ascending order\n",
        "    req_tfidf = flat[-2]  # Get the second highest cosine similarity value\n",
        "    if req_tfidf == 0:\n",
        "        chatbot_response = chatbot_response + \"I am sorry! I don't understand you\"  # If the similarity is 0, the chatbot doesn't understand the user's input\n",
        "        return chatbot_response\n",
        "    else:\n",
        "        chatbot_response = sent_tokens[idx]  # Retrieve the most similar sentence token as the chatbot's response\n",
        "        return chatbot_response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpoDyTfx9enu",
        "outputId": "c9fd35e5-2cc2-4301-b473-76603ffa6166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: Hi, my name is Chatbot. I will answer your queries about Hugging face. If you want to exit, type 'Bye!'\n",
            "hi\n",
            "Chatbot: hi\n",
            "year\n",
            "Chatbot: find sources: \"hugging face\" – news · newspapers · books · scholar · jstor (february 2023) (learn how and when to remove this template message)\n",
            "hugging face, inc.\n",
            "hugging face logo.png\n",
            "type\tprivate\n",
            "industry\tartificial intelligence, machine learning, software development\n",
            "founded\t2016; 7 years ago in new york city\n",
            "headquarters\tnew york city, u.s.\n",
            "area served\tworldwide\n",
            "key people\t\n",
            "clément delangue (ceo)\n",
            "julien chaumond (cto)\n",
            "thomas wolf (cso)\n",
            "products\ttransformers, datasets, spaces\n",
            "website\thuggingface.co\n",
            "hugging face, inc. is an american company that develops tools for building applications using machine learning.\n",
            "hhhtyhg\n",
            "Chatbot:  I am sorry! I don't understand you\n"
          ]
        }
      ],
      "source": [
        "# Create empty lists to store user responses and chatbot responses\n",
        "user_responses = []\n",
        "chatbot_responses = []\n",
        "\n",
        "n = True\n",
        "print(\"Chatbot: Hi, my name is Chatbot. I will answer your queries about Hugging face. If you want to exit, type 'Bye!'\")\n",
        "\n",
        "while n:\n",
        "    user_response = input()\n",
        "    user_response = user_response.lower()\n",
        "    if user_response in [\"bye\", \"goodbye\"]:\n",
        "        n = False\n",
        "        print(\"Chatbot: Bye! Take care.\")\n",
        "    else:\n",
        "        if user_response in [\"thanks\", \"thank you\"]:\n",
        "            n = False\n",
        "            print(\"Chatbot: You're welcome.\")\n",
        "        else:\n",
        "            greeting_result = greeting(user_response)\n",
        "            if greeting_result is not None:\n",
        "                print(\"Chatbot: \" + greeting_result)\n",
        "            else:\n",
        "                print(\"Chatbot: \", end=\"\")\n",
        "                chatbot_response = response(user_response)\n",
        "                print(chatbot_response)\n",
        "                sent_tokens.remove(user_response)\n",
        "                \n",
        "                # Append the user and chatbot responses to the respective lists\n",
        "                user_responses.append(user_response)\n",
        "                chatbot_responses.append(chatbot_response)\n",
        "\n",
        "# Create a DataFrame using the collected responses\n",
        "data = {'user_response': user_responses, 'chatbot_response': chatbot_responses}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(range(len(df)), df['chatbot_response'])\n",
        "plt.xlabel('Interaction')\n",
        "plt.ylabel('Chatbot Response')\n",
        "plt.title('Chatbot Responses')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEMWW0CnhXkC"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
